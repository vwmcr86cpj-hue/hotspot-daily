import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def get_weibo_hot():
    """å¾®åšçƒ­æœæµ‹è¯•ï¼ˆç›¸å¯¹ç®€å•ï¼‰"""
    url = "https://s.weibo.com/top/summary"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Cookie": "",  # å¯ä»¥ç•™ç©ºè¯•è¯•
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2"
    }
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] æµ‹è¯•å¾®åšçƒ­æœ...")
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å¾®åšçƒ­æœé€šå¸¸åœ¨<td>æ ‡ç­¾ä¸­
            hot_items = []
            
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾çƒ­æœåˆ—è¡¨
            for td in soup.find_all('td', class_='td-02'):
                link = td.find('a')
                if link and link.text.strip():
                    title = link.text.strip()
                    href = link.get('href', '')
                    
                    # æå–çƒ­åº¦
                    span = td.find('span')
                    hot = span.text if span else ''
                    
                    hot_items.append({
                        'title': title,
                        'url': f"https://s.weibo.com{href}" if href.startswith('/') else href,
                        'hot': hot
                    })
            
            if hot_items:
                print(f"âœ… æˆåŠŸè·å– {len(hot_items)} æ¡å¾®åšçƒ­æœ")
                for i, item in enumerate(hot_items[:10], 1):
                    print(f"{i}. {item['title'][:20]}... {item['hot']}")
                return True
            else:
                # æ–¹æ³•2ï¼šå°è¯•å…¶ä»–é€‰æ‹©å™¨
                print("âš ï¸ æ–¹æ³•1å¤±è´¥ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨...")
                
                # å¾®åšå¯èƒ½ç”¨å…¶ä»–ç»“æ„
                for a in soup.find_all('a'):
                    href = a.get('href', '')
                    if '/weibo?q=' in href and a.text.strip():
                        print(f"  å¤‡é€‰: {a.text[:20]}...")
                
                return False
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ å¾®åšçƒ­æœè·å–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = get_weibo_hot()
    if success:
        print("\nğŸ¯ å¾®åšçƒ­æœæµ‹è¯•æˆåŠŸï¼")
    else:
        print("\nğŸ”§ å»ºè®®ï¼š")
        print("1. æ£€æŸ¥ç½‘ç»œæ˜¯å¦å¯ä»¥è®¿é—®å¾®åš")
        print("2. å¯èƒ½éœ€è¦æ›´æ–°é€‰æ‹©å™¨")
