"""
Bç«™çƒ­ç‚¹æ•°æ®æ”¶é›†
åŒ…å«ï¼šçƒ­é—¨è§†é¢‘æ’è¡Œæ¦œã€çƒ­æœè¯
"""
import requests
import json
from datetime import datetime
import time

class BilibiliCrawler:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://www.bilibili.com"
        }
        
    def get_ranking(self, rid=0, day=3, page_size=20):
        """
        è·å–Bç«™æ’è¡Œæ¦œ
        Args:
            rid: åˆ†åŒºID (0:å…¨ç«™, 1:åŠ¨ç”», 3:éŸ³ä¹, 4:æ¸¸æˆ, 5:å¨±ä¹, 36:ç§‘æŠ€, 160:ç”Ÿæ´», 119:é¬¼ç•œ, 129:èˆè¹ˆ)
            day: 1(æ—¥æ¦œ), 3(ä¸‰æ—¥æ¦œ), 7(å‘¨æ¦œ)
            page_size: æ¯é¡µæ•°é‡
        """
        url = "https://api.bilibili.com/x/web-interface/ranking/v2"
        params = {
            "rid": rid,
            "type": "all",
            "day": day,
            "page_size": page_size
        }
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] è·å–Bç«™æ’è¡Œæ¦œ (åˆ†åŒº: {rid})...")
        
        try:
            response = requests.get(url, params=params, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("code") == 0:
                    videos = data.get("data", {}).get("list", [])
                    
                    result = []
                    for i, video in enumerate(videos[:page_size], 1):
                        video_info = {
                            "rank": i,
                            "bvid": video.get("bvid", ""),
                            "title": video.get("title", ""),
                            "url": f"https://www.bilibili.com/video/{video.get('bvid', '')}",
                            "up": video.get("owner", {}).get("name", ""),
                            "duration": video.get("duration", 0),  # ç§’
                            "view": video.get("stat", {}).get("view", 0),
                            "danmaku": video.get("stat", {}).get("danmaku", 0),
                            "like": video.get("stat", {}).get("like", 0),
                            "coin": video.get("stat", {}).get("coin", 0),
                            "favorite": video.get("stat", {}).get("favorite", 0),
                            "share": video.get("stat", {}).get("share", 0),
                            "reply": video.get("stat", {}).get("reply", 0),
                            "category": self._get_category_name(rid)
                        }
                        result.append(video_info)
                    
                    print(f"âœ… è·å–åˆ° {len(result)} ä¸ªçƒ­é—¨è§†é¢‘")
                    return result
                else:
                    print(f"âš ï¸ APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ è·å–å¤±è´¥: {e}")
        
        return []
    
    def get_hot_search(self):
        """è·å–Bç«™çƒ­æœæ¦œ"""
        url = "https://app.bilibili.com/x/v2/search/trending/ranking"
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] è·å–Bç«™çƒ­æœ...")
        
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("code") == 0:
                    hot_words = data.get("data", {}).get("list", [])
                    
                    result = []
                    for i, word in enumerate(hot_words[:20], 1):
                        word_info = {
                            "rank": i,
                            "keyword": word.get("keyword", ""),
                            "show_name": word.get("show_name", ""),
                            "url": f"https://search.bilibili.com/all?keyword={word.get('keyword', '')}",
                            "icon": word.get("icon", ""),
                            "heat": word.get("heat", 0)
                        }
                        result.append(word_info)
                    
                    print(f"âœ… è·å–åˆ° {len(result)} ä¸ªçƒ­æœè¯")
                    return result
                else:
                    print(f"âš ï¸ çƒ­æœAPIé”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"âŒ çƒ­æœè¯·æ±‚å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ çƒ­æœè·å–å¤±è´¥: {e}")
        
        return []
    
    def _get_category_name(self, rid):
        """æ ¹æ®åˆ†åŒºIDè·å–åˆ†åŒºåç§°"""
        categories = {
            0: "å…¨ç«™",
            1: "åŠ¨ç”»",
            3: "éŸ³ä¹",
            4: "æ¸¸æˆ",
            5: "å¨±ä¹",
            36: "ç§‘æŠ€",
            119: "é¬¼ç•œ",
            129: "èˆè¹ˆ",
            155: "æ—¶å°š",
            160: "ç”Ÿæ´»",
            168: "å›½åˆ›",
            188: "æ•°ç "
        }
        return categories.get(rid, f"åˆ†åŒº{rid}")
    
    def save_to_file(self, data, filename_prefix="bilibili"):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if not data:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return None
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"data/{filename_prefix}_{timestamp}.json"
        
        os.makedirs("data", exist_ok=True)
        
        save_data = {
            "platform": "bilibili",
            "timestamp": datetime.now().isoformat(),
            "data": data
        }
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        return filename

def test_bilibili():
    """æµ‹è¯•Bç«™çˆ¬è™«"""
    print("=" * 60)
    print("Bç«™çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    
    crawler = BilibiliCrawler()
    
    # 1. æµ‹è¯•å…¨ç«™çƒ­é—¨
    print("\n1. æµ‹è¯•å…¨ç«™çƒ­é—¨è§†é¢‘:")
    videos = crawler.get_ranking(rid=0, page_size=10)
    
    if videos:
        print("\nğŸ† çƒ­é—¨è§†é¢‘TOP5:")
        for video in videos[:5]:
            view_str = f"{video['view']:,}" if video['view'] < 10000 else f"{video['view']/10000:.1f}ä¸‡"
            print(f"{video['rank']:2d}. {video['title'][:30]:30}...")
            print(f"     UP: {video['up'][:10]:10} ğŸ‘€{view_str:>8} ğŸ‘{video['like']:,}")
    
    time.sleep(2)
    
    # 2. æµ‹è¯•çƒ­æœ
    print("\n2. æµ‹è¯•çƒ­æœæ¦œ:")
    hot_search = crawler.get_hot_search()
    
    if hot_search:
        print("\nğŸ”¥ çƒ­æœTOP5:")
        for item in hot_search[:5]:
            print(f"{item['rank']:2d}. {item['keyword'][:20]}")
    
    # 3. ä¿å­˜æ•°æ®
    if videos or hot_search:
        all_data = {
            "ranking": videos,
            "hot_search": hot_search
        }
        crawler.save_to_file(all_data, "bilibili_full")
        
        print("\n" + "=" * 60)
        print("ğŸ¯ Bç«™çˆ¬è™«æµ‹è¯•å®Œæˆï¼")
        if videos:
            print(f"  çƒ­é—¨è§†é¢‘: {len(videos)} ä¸ª")
        if hot_search:
            print(f"  çƒ­æœè¯: {len(hot_search)} ä¸ª")
    else:
        print("\nâŒ Bç«™çˆ¬è™«æµ‹è¯•å¤±è´¥")
    
    return videos or hot_search

if __name__ == "__main__":
    import os
    test_bilibili()
